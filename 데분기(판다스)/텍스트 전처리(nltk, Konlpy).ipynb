{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1d47d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name               email                 description\n",
      "0    Alice   alice@example.com  Alice is a Data Scientist.\n",
      "1      Bob     bob@example.com         Bob is an Engineer.\n",
      "2  Charlie  charlie@sample.net        Charlie is a Doctor.\n",
      "3    David   david@website.org          David is a Lawyer.\n",
      "4      Eve      eve@domain.com           Eve is an Artist.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 샘플 데이터프레임 생성\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'email': ['alice@example.com', 'bob@example.com', 'charlie@sample.net', 'david@website.org', 'eve@domain.com'],\n",
    "    'description': ['Alice is a Data Scientist.', 'Bob is an Engineer.', 'Charlie is a Doctor.', 'David is a Lawyer.', 'Eve is an Artist.']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a8f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cat 데이터 붙이기\n",
    "df['name+email']=df['name'].str.cat(df['email'],sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fd943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 나누기\n",
    "df[['userid','domain']]=df['email'].str.split('@',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5375631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A\n",
       "1    B\n",
       "2    C\n",
       "3    D\n",
       "4    E\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get으로 문자의 특정 위치값을 가지고 올 수 있다.\n",
    "df['name'].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d006304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Al\n",
       "1    Bo\n",
       "2    Ch\n",
       "3    Da\n",
       "4    Ev\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 슬라이스\n",
    "df['name'].str.slice(start=0, stop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ebf314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>website.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>domain.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0  example.com\n",
       "1  example.com\n",
       "2   sample.net\n",
       "3  website.org\n",
       "4   domain.com"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## extract, 정규표현식 추출\n",
    "df['email'].str.extract(r'@(\\w+\\.\\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a4bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>description</th>\n",
       "      <th>name+email</th>\n",
       "      <th>userid</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>alice@example.com</td>\n",
       "      <td>Alice is a Data Scientist.</td>\n",
       "      <td>Alice/alice@example.com</td>\n",
       "      <td>alice</td>\n",
       "      <td>example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>bob@example.com</td>\n",
       "      <td>Bob is an Engineer.</td>\n",
       "      <td>Bob/bob@example.com</td>\n",
       "      <td>bob</td>\n",
       "      <td>example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>charlie@sample.net</td>\n",
       "      <td>Charlie is a Doctor.</td>\n",
       "      <td>Charlie/charlie@sample.net</td>\n",
       "      <td>charlie</td>\n",
       "      <td>sample.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>david@website.org</td>\n",
       "      <td>David is a Lawyer.</td>\n",
       "      <td>David/david@website.org</td>\n",
       "      <td>david</td>\n",
       "      <td>website.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>eve@domain.com</td>\n",
       "      <td>Eve is an Artist.</td>\n",
       "      <td>Eve/eve@domain.com</td>\n",
       "      <td>eve</td>\n",
       "      <td>domain.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name               email                 description  \\\n",
       "0    Alice   alice@example.com  Alice is a Data Scientist.   \n",
       "1      Bob     bob@example.com         Bob is an Engineer.   \n",
       "2  Charlie  charlie@sample.net        Charlie is a Doctor.   \n",
       "3    David   david@website.org          David is a Lawyer.   \n",
       "4      Eve      eve@domain.com           Eve is an Artist.   \n",
       "\n",
       "                   name+email   userid       domain  \n",
       "0     Alice/alice@example.com    alice  example.com  \n",
       "1         Bob/bob@example.com      bob  example.com  \n",
       "2  Charlie/charlie@sample.net  charlie   sample.net  \n",
       "3     David/david@website.org    david  website.org  \n",
       "4          Eve/eve@domain.com      eve   domain.com  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cac2f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>Charlie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>Eve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "  match           \n",
       "0 0          Alice\n",
       "  1             is\n",
       "  2              a\n",
       "  3           Data\n",
       "  4      Scientist\n",
       "1 0            Bob\n",
       "  1             is\n",
       "  2             an\n",
       "  3       Engineer\n",
       "2 0        Charlie\n",
       "  1             is\n",
       "  2              a\n",
       "  3         Doctor\n",
       "3 0          David\n",
       "  1             is\n",
       "  2              a\n",
       "  3         Lawyer\n",
       "4 0            Eve\n",
       "  1             is\n",
       "  2             an\n",
       "  3         Artist"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식에 일치하는 모든 부분 추출 extractall\n",
    "df['description'].str.extractall(r'(\\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2833b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Alice  a Data Scientt.\n",
       "1         Bob  an Engineer.\n",
       "2        Charlie  a Doctor.\n",
       "3          David  a Lawyer.\n",
       "4             Eve  an Artt.\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace\n",
    "df['description'].str.replace('is','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31d7216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -1\n",
       "1    -1\n",
       "2    -1\n",
       "3    -1\n",
       "4    10\n",
       "Name: description, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find\n",
    "df['description'].str.find('Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d941683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "Name: description, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#문자열이 포함되어 있는지\n",
    "#contains\n",
    "df['description'].str.contains('Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b94f35dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>description</th>\n",
       "      <th>name+email</th>\n",
       "      <th>userid</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>eve@domain.com</td>\n",
       "      <td>Eve is an Artist.</td>\n",
       "      <td>Eve/eve@domain.com</td>\n",
       "      <td>eve</td>\n",
       "      <td>domain.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name           email        description          name+email userid  \\\n",
       "4  Eve  eve@domain.com  Eve is an Artist.  Eve/eve@domain.com    eve   \n",
       "\n",
       "       domain  \n",
       "4  domain.com  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loc 이랑 응용하면 \n",
    "#& 문으로 다양하게 엮을 수 있다.\n",
    "df.loc[df['description'].str.contains('Artist')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c501518a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain.com</th>\n",
       "      <th>example.com</th>\n",
       "      <th>sample.net</th>\n",
       "      <th>website.org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain.com  example.com  sample.net  website.org\n",
       "0           0            1           0            0\n",
       "1           0            1           0            0\n",
       "2           0            0           1            0\n",
       "3           0            0           0            1\n",
       "4           1            0           0            0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get_dummies\n",
    "## 인코딩하는 작업으로\n",
    "df['domain'].str.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "031a2c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>description</th>\n",
       "      <th>name+email</th>\n",
       "      <th>userid</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>alice@example.com</td>\n",
       "      <td>Alice is a Data Scientist.</td>\n",
       "      <td>Alice/alice@example.com</td>\n",
       "      <td>alice</td>\n",
       "      <td>example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>bob@example.com</td>\n",
       "      <td>Bob is an Engineer.</td>\n",
       "      <td>Bob/bob@example.com</td>\n",
       "      <td>bob</td>\n",
       "      <td>example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>charlie@sample.net</td>\n",
       "      <td>Charlie is a Doctor.</td>\n",
       "      <td>Charlie/charlie@sample.net</td>\n",
       "      <td>charlie</td>\n",
       "      <td>sample.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>david@website.org</td>\n",
       "      <td>David is a Lawyer.</td>\n",
       "      <td>David/david@website.org</td>\n",
       "      <td>david</td>\n",
       "      <td>website.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>eve@domain.com</td>\n",
       "      <td>Eve is an Artist.</td>\n",
       "      <td>Eve/eve@domain.com</td>\n",
       "      <td>eve</td>\n",
       "      <td>domain.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name               email                 description  \\\n",
       "0    Alice   alice@example.com  Alice is a Data Scientist.   \n",
       "1      Bob     bob@example.com         Bob is an Engineer.   \n",
       "2  Charlie  charlie@sample.net        Charlie is a Doctor.   \n",
       "3    David   david@website.org          David is a Lawyer.   \n",
       "4      Eve      eve@domain.com           Eve is an Artist.   \n",
       "\n",
       "                   name+email   userid       domain  \n",
       "0     Alice/alice@example.com    alice  example.com  \n",
       "1         Bob/bob@example.com      bob  example.com  \n",
       "2  Charlie/charlie@sample.net  charlie   sample.net  \n",
       "3     David/david@website.org    david  website.org  \n",
       "4          Eve/eve@domain.com      eve   domain.com  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad52be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['description','userid']].str.contains('Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb4b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].str.contains('Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f2637",
   "metadata": {},
   "source": [
    "- 시리즈로 접근해서 처리한 후 -> 데이터프레임으로 같이 연결하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('movie_rv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f055e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구분자를 넣고 여러 컬럼을 나눠보기!\n",
    "df['document'].str.split(' ',n=1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 3개 이상 나누고 싶다.\n",
    "df['document'].str.partition(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6993a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식으로 특정 단어 추출\n",
    "df['document'].str.findall('[재미]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f90c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##리뷰에 대한 수치를 시각적으로 볼 수 있다.\n",
    "\n",
    "df['document_len']=df['document'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b744c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['document_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label')['document_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb3247",
   "metadata": {},
   "source": [
    "### 정형데이터와는 다르게 비정형데이터( 리뷰데이터 ) \n",
    "- 어떤 점이 차이가 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7181f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "sns.load_dataset('titanic').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1035fb",
   "metadata": {},
   "source": [
    "## 텍스트 전처리\n",
    "- 영문, 한국어\n",
    "- 영문부터 패키지가지고 학습할 예정\n",
    "- 자연어처리 (NLP) 인간의 언어- > 컴퓨터가 이해할 수 있도록 처리를 해야 한다. 컴퓨터가 분석할 수 있도록 프로그래밍하는 방법!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef518eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89827fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jun/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to /Users/jun/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jun/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/jun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jun/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk 라이브러리 \n",
    "nltk.download('punkt')\n",
    "nltk.download('webtext')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30a1591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is the kind you take with you through the rest of your life.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Deep learning is the kind you take with you through the rest of your life.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c104a701",
   "metadata": {},
   "source": [
    "- 전처리 단계 \n",
    "- 텍스트에 대한 전처리 단계 \n",
    "- 주어진 텍스트의 노이즈나 분석에 불필요한 것들이 분명 존재, 제거하고 문장들을 나눠서 분석할 수 있다. 표준 단어나 이런 것들로 분리하고, 품사나 파악하는 것 \n",
    "- 한국어, 영어는 다르니깐 전처리 어느정도 다를 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab7b41",
   "metadata": {},
   "source": [
    "- 정제 : (정규표현식 등으로 데이터에 노이즈를 제거하거나, 필요한 것들만 추출하는 작업)\n",
    "- 토큰화 : (주어진 텍스트를 원하는 단위로 나누는 것 (Token) 단어 토큰화, 다른 방법으로도 토큰을 나눌 수 있다. 딥러닝에서 성능을 올리기 위해 토큰화 작업 진행)\n",
    "- 정규화 : (동사의 변형들, 과거형이나 등등 결국 하나의 동사에 의미), 어간 추출, 표제어 추출 등으로 작업할 수 있다.\n",
    "- 품사 태깅 : (명사, 대명사, 형용사 등등) 앞서 토큰을 나눴으면 -> 의미를 부여할 수 있다. 품사를 알려주면서 더 많은 의미있는 데이터를 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cf831c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.[2]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af47b9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.[2]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01f45f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning.', 'The adjective \"deep\" refers to the use of multiple layers in the network.', 'Methods used can be either supervised, semi-supervised or unsupervised.', '[2]']\n"
     ]
    }
   ],
   "source": [
    "#문장에 대한 토큰화\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print(sent_tokenize(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "706ab90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'is', 'the', 'subset', 'of', 'machine', 'learning', 'methods', 'based', 'on', 'artificial', 'neural', 'networks', 'with', 'representation', 'learning', '.', 'The', 'adjective', '``', 'deep', \"''\", 'refers', 'to', 'the', 'use', 'of', 'multiple', 'layers', 'in', 'the', 'network', '.', 'Methods', 'used', 'can', 'be', 'either', 'supervised', ',', 'semi-supervised', 'or', 'unsupervised', '.', '[', '2', ']']\n"
     ]
    }
   ],
   "source": [
    "#단어 토큰화\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(word_tokenize(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d63036f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'is', 'the', 'subset', 'of', 'machine', 'learning', 'methods', 'based', 'on', 'artificial', 'neural', 'networks', 'with', 'representation', 'learning', '.', 'The', 'adjective', '\"', 'deep', '\"', 'refers', 'to', 'the', 'use', 'of', 'multiple', 'layers', 'in', 'the', 'network', '.', 'Methods', 'used', 'can', 'be', 'either', 'supervised', ',', 'semi', '-', 'supervised', 'or', 'unsupervised', '.[', '2', ']']\n"
     ]
    }
   ],
   "source": [
    "# 특수문자등을 처리할 수 있다.\n",
    "# 제거해 주는 패키\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "# 특수문자 제거\n",
    "print(WordPunctTokenizer().tokenize(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1a260ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규표현식도 같이 토크나이즈\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tk= RegexpTokenizer('[\\w\"]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78e9f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep', 'learning', 'is', 'the', 'subset', 'of', 'machine', 'learning', 'methods', 'based', 'on', 'artificial', 'neural', 'networks', 'with', 'representation', 'learning', 'The', 'adjective', '\"deep\"', 'refers', 'to', 'the', 'use', 'of', 'multiple', 'layers', 'in', 'the', 'network', 'Methods', 'used', 'can', 'be', 'either', 'supervised', 'semi', 'supervised', 'or', 'unsupervised', '2']\n"
     ]
    }
   ],
   "source": [
    "#내가 원하는 정규표현식에 따라 데이터가 전처리가 진행이 되었다.\n",
    "print(tk.tokenize(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35339e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 처리 (노이즈)\n",
    "#은,는,이,가 의미가 없다고 보는 단어들\n",
    "#영어도 불용어처리 진행\n",
    "from nltk.corpus import stopwords #불용어 가져오는 패키지\n",
    "\n",
    "en_stops=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a6b4a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 다양한 패키지를 응용해서 전처리를 할 수 있다. (정제 가능)\n",
    "en_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbfbd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tk.tokenize(df.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9057bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deep', 'learning', 'subset', 'machine', 'learning', 'methods', 'based', 'artificial', 'neural', 'networks', 'representation', 'learning', 'adjective', '\"deep\"', 'refers', 'use', 'multiple', 'layers', 'network', 'methods', 'used', 'either', 'supervised', 'semi', 'supervised', 'unsupervised', '2']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in tokens if word not in en_stops]) # 불용어처리는 제외한 단어만 전처리가 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd0019d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.[2]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e87218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##표제어 추출\n",
    "##단어 기본형 변환\n",
    "##cooking cook, cooks, cookie, cookbooks, 등등\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemm =WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4083e64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooking\n",
      "cookking\n",
      "cook\n",
      "cooker\n",
      "cooker\n"
     ]
    }
   ],
   "source": [
    "print(lemm.lemmatize('cooking'))\n",
    "print(lemm.lemmatize('cookking'))\n",
    "print(lemm.lemmatize('cookss'))\n",
    "print(lemm.lemmatize('cooker'))\n",
    "print(lemm.lemmatize('cookers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b572c707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Deep', 'JJ'), ('learning', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('subset', 'NN'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'VBG'), ('methods', 'NNS'), ('based', 'VBN'), ('on', 'IN'), ('artificial', 'JJ'), ('neural', 'JJ'), ('networks', 'NNS'), ('with', 'IN'), ('representation', 'NN'), ('learning', 'NN'), ('.', '.'), ('The', 'DT'), ('adjective', 'JJ'), ('``', '``'), ('deep', 'JJ'), (\"''\", \"''\"), ('refers', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('multiple', 'JJ'), ('layers', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('network', 'NN'), ('.', '.'), ('Methods', 'NNS'), ('used', 'VBD'), ('can', 'MD'), ('be', 'VB'), ('either', 'RB'), ('supervised', 'VBN'), (',', ','), ('semi-supervised', 'JJ'), ('or', 'CC'), ('unsupervised', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "##품사 태깅\n",
    "##토큰화 -> 정규화 과정 통해서 나온 결과를 형태소 정리한 내용\n",
    "#형태소라는 건 의미를 가지고 있는 작은 말의 단위 더 나누게 되면 본래 뜻을 잃을 수 있다.\n",
    "#형태소 -> 형, 태소, 형, 태, 소 의미가 사라진다.\n",
    "#형태소까지 가지 않더라도, 텍스트마이닝에서 품사라는 것을 사용해서 좀 더 의미를 잃지 않고 학습시킬 수 있다.\n",
    "\n",
    "\n",
    "## 명사, 대명사, 동사, 형용사...  \n",
    "## 명사는 어떤 식으로 사용하는지, 동사는 어떤 식으로 사용하는지 명칭 \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tk=word_tokenize('Deep learning is the subset of machine learning methods based on artificial neural networks with representation learning. The adjective \"deep\" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised')\n",
    "print(nltk.pos_tag(tk))\n",
    "##(단어, 품사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f974084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_tag = ['JJ']\n",
    "jj_tag = [ word for word, tag in nltk.pos_tag(tk) if tag in wt_tag ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f970121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'adjective',\n",
       " 'deep',\n",
       " 'multiple',\n",
       " 'semi-supervised',\n",
       " 'unsupervised']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49879128",
   "metadata": {},
   "source": [
    "## 한글 형태소 분석, 품사 태깅 가능하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ff1bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KoNLPy(kkma, twitter, mecab, okt, hannaum)\n",
    "## 품사 태깅등, 전처리 패키지가 다양하다.\n",
    "## https://konlpy.org/ko/latest/\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1512d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#패키지를 불러오기!\n",
    "k = Okt()\n",
    "\n",
    "#Okt\n",
    "#morphase(phrase) : 텍스트를 형태로 단위로 분리\n",
    "#nouns(phrase) : 명사만 분리해서 보여준다.\n",
    "#pos(phrase) : 태깅해서 보여준다.\n",
    "\n",
    "data = '''🌟안녕하세요 BDA 운영진입니다!🌟\n",
    "여름방학을 맞아 학회원 여러분의 데이터 역량을 늘릴 수 있는 찍어먹어BDA 부트캠프를 진행합니다!\n",
    "\n",
    "찍어먹어 BDA는 데이터 시각화, 클라우드 등 데이터와 관련된 역량을 기를 수 있는 원데이 클래스들로 이루어져 있습니다!\n",
    "자세한 원데이 클래스는 아래 카드뉴스에서 확인 가능합니다!\n",
    "많은 참여 부탁드립니다~\n",
    "\n",
    "7월 28일까지 아래의 구글폼에 응답해주세요!\n",
    "찍어먹어 BDA 모집 구글폼 : https://forms.gle/K5aSFk463uRPZRqZ9'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbca3ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🌟안녕하세요 BDA 운영진입니다!🌟\\n여름방학을 맞아 학회원 여러분의 데이터 역량을 늘릴 수 있는 찍어먹어BDA 부트캠프를 진행합니다!\\n\\n찍어먹어 BDA는 데이터 시각화, 클라우드 등 데이터와 관련된 역량을 기를 수 있는 원데이 클래스들로 이루어져 있습니다!\\n자세한 원데이 클래스는 아래 카드뉴스에서 확인 가능합니다!\\n많은 참여 부탁드립니다~\\n\\n7월 28일까지 아래의 구글폼에 응답해주세요!\\n찍어먹어 BDA 모집 구글폼 : https://forms.gle/K5aSFk463uRPZRqZ9'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16e1e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['운영', '진입', '니', '여름방학', '학회', '여러분', '데이터', '역량', '수', '부트캠프', '진행', '데이터', '시각', '클라우드', '등', '데이터', '관련', '역량', '수', '원데이', '클래스', '원데이', '클래스', '아래', '카드', '뉴스', '확인', '참여', '아래', '구글', '폼', '응답', '모집', '구글', '폼']\n"
     ]
    }
   ],
   "source": [
    "print(k.nouns(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97d3bf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🌟', 'Foreign'), ('안녕하세요', 'Adjective'), ('BDA', 'Alpha'), ('운영', 'Noun'), ('진입', 'Noun'), ('니', 'Noun'), ('다', 'Josa'), ('!', 'Punctuation'), ('🌟', 'Foreign'), ('\\n', 'Foreign'), ('여름방학', 'Noun'), ('을', 'Josa'), ('맞아', 'Verb'), ('학회', 'Noun'), ('원', 'Suffix'), ('여러분', 'Noun'), ('의', 'Josa'), ('데이터', 'Noun'), ('역량', 'Noun'), ('을', 'Josa'), ('늘릴', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('찍어', 'Verb'), ('먹어', 'Verb'), ('BDA', 'Alpha'), ('부트캠프', 'Noun'), ('를', 'Josa'), ('진행', 'Noun'), ('합니다', 'Verb'), ('!', 'Punctuation'), ('\\n\\n', 'Foreign'), ('찍어', 'Verb'), ('먹어', 'Verb'), ('BDA', 'Alpha'), ('는', 'Verb'), ('데이터', 'Noun'), ('시각', 'Noun'), ('화', 'Suffix'), (',', 'Punctuation'), ('클라우드', 'Noun'), ('등', 'Noun'), ('데이터', 'Noun'), ('와', 'Josa'), ('관련', 'Noun'), ('된', 'Verb'), ('역량', 'Noun'), ('을', 'Josa'), ('기를', 'Verb'), ('수', 'Noun'), ('있는', 'Adjective'), ('원데이', 'Noun'), ('클래스', 'Noun'), ('들', 'Suffix'), ('로', 'Josa'), ('이루어져', 'Verb'), ('있습니다', 'Adjective'), ('!', 'Punctuation'), ('\\n', 'Foreign'), ('자세한', 'Adjective'), ('원데이', 'Noun'), ('클래스', 'Noun'), ('는', 'Josa'), ('아래', 'Noun'), ('카드', 'Noun'), ('뉴스', 'Noun'), ('에서', 'Josa'), ('확인', 'Noun'), ('가능합니다', 'Adjective'), ('!', 'Punctuation'), ('\\n', 'Foreign'), ('많은', 'Adjective'), ('참여', 'Noun'), ('부탁드립니다', 'Adjective'), ('~', 'Punctuation'), ('\\n\\n', 'Foreign'), ('7월', 'Number'), ('28일', 'Number'), ('까지', 'Foreign'), ('아래', 'Noun'), ('의', 'Josa'), ('구글', 'Noun'), ('폼', 'Noun'), ('에', 'Josa'), ('응답', 'Noun'), ('해주세요', 'Verb'), ('!', 'Punctuation'), ('\\n', 'Foreign'), ('찍어', 'Verb'), ('먹어', 'Verb'), ('BDA', 'Alpha'), ('모집', 'Noun'), ('구글', 'Noun'), ('폼', 'Noun'), (':', 'Punctuation'), ('https://forms.gle/K5aSFk463uRPZRqZ9', 'URL')]\n"
     ]
    }
   ],
   "source": [
    "print(k.pos(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6659c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('movie_rv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2ea7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#na값 확인\n",
    "df['document']=df['document'].fillna(0)\n",
    "df['document']=df['document'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "defa7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp=df.iloc[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d6c56d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29995</td>\n",
       "      <td>5277532</td>\n",
       "      <td>ㅁ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29996</td>\n",
       "      <td>6308533</td>\n",
       "      <td>멘탈붕괴...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29997</td>\n",
       "      <td>6148618</td>\n",
       "      <td>마지막 2분 남겨놓은 노래 제목좀 가르쳐 주세요~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29998</td>\n",
       "      <td>3908341</td>\n",
       "      <td>어쩌면 이렇게 아름다운 영화를 만들수 있을까...보는내내 참 행복했다:)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>29999</td>\n",
       "      <td>8435032</td>\n",
       "      <td>수작은 개뿔.. 지루한 아일랜드 혁명 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        id  \\\n",
       "0               0   9976970   \n",
       "1               1   3819312   \n",
       "2               2  10265843   \n",
       "3               3   9045019   \n",
       "4               4   6483659   \n",
       "...           ...       ...   \n",
       "29995       29995   5277532   \n",
       "29996       29996   6308533   \n",
       "29997       29997   6148618   \n",
       "29998       29998   3908341   \n",
       "29999       29999   8435032   \n",
       "\n",
       "                                                document  label  \n",
       "0                                    아 더빙.. 진짜 짜증나네요 목소리      0  \n",
       "1                      흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1  \n",
       "2                                      너무재밓었다그래서보는것을추천한다      0  \n",
       "3                          교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0  \n",
       "4      사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1  \n",
       "...                                                  ...    ...  \n",
       "29995                                                  ㅁ      1  \n",
       "29996                                            멘탈붕괴...      0  \n",
       "29997                        마지막 2분 남겨놓은 노래 제목좀 가르쳐 주세요~      1  \n",
       "29998           어쩌면 이렇게 아름다운 영화를 만들수 있을까...보는내내 참 행복했다:)      1  \n",
       "29999                            수작은 개뿔.. 지루한 아일랜드 혁명 영화      0  \n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837cb69",
   "metadata": {},
   "source": [
    "## 문서에 대한 카운트 기반으로 생각할 수 있다.\n",
    "- CountVectorizer 패키지를 사용하면 쉽게 벡터화해서 데이터를 전처리할 수 있다.\n",
    "- {'원데이':3, '클래스':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "691723c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62e71272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 사용한 피처는 무엇인지 확인하는 것! ['and' 'corpus' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "----\n",
      "내가 원하는 메트릭스를 보고 싶다! [[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 1 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 예시 리스트\n",
    "corpus= [\n",
    "    'This is the first corpus',\n",
    "    'This corpus is the second corpus',\n",
    "    'And this corpus is the third one',\n",
    "    'Is this the first corpus?'\n",
    "]\n",
    "\n",
    "#CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "\n",
    "# 문서를 벡터화\n",
    "X =cv.fit_transform(corpus)\n",
    "\n",
    "# 변환 결과를 출력\n",
    "print('corpus 사용한 피처는 무엇인지 확인하는 것!',cv.get_feature_names_out())\n",
    "print('----')\n",
    "print('내가 원하는 메트릭스를 보고 싶다!',X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c633fa",
   "metadata": {},
   "source": [
    "- ['and' 'corpus' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
    "- corpus 의 리스트[0]~[3] 리뷰에 카운팅을 계산해서 -> 행렬 변환이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b11a99b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df5a7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한국어로 진행\n",
    "corpus_ko=[\n",
    "    '오늘 날씨는 매우 좋습니다',\n",
    "    '내일 날씨는 매우 좋을까요',\n",
    "    '내일은 비가 올 것 같습니다',\n",
    "    '모두 내일은 우산을 준비하세요',\n",
    "    'BDA는 이제 곧 9기를 모집합니다',\n",
    "    '우리는 열심히 공부합니다',\n",
    "    '우리는 내일도 공부합니다'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12fa0fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 사용한 피처는 무엇인지 확인하는 것! ['9기를' 'bda는' '같습니다' '공부합니다' '날씨는' '내일' '내일도' '내일은' '매우' '모두' '모집합니다' '비가'\n",
      " '열심히' '오늘' '우리는' '우산을' '이제' '좋습니다' '좋을까요' '준비하세요']\n",
      "----\n",
      "내가 원하는 메트릭스를 보고 싶다! [[0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1]\n",
      " [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "\n",
    "# 문서를 벡터화\n",
    "X =cv.fit_transform(corpus_ko)\n",
    "\n",
    "# 변환 결과를 출력\n",
    "print('corpus 사용한 피처는 무엇인지 확인하는 것!',cv.get_feature_names_out())\n",
    "print('----')\n",
    "print('내가 원하는 메트릭스를 보고 싶다!',X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98c773c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한국어로 진행\n",
    "corpus_ko=[\n",
    "    '오늘 날씨는 매우 좋습니다',\n",
    "    '내일 날씨는 매우 좋을까요',\n",
    "    '내일은 비가 올 것 같습니다',\n",
    "    '모두 내일은 우산을 준비하세요',\n",
    "    'BDA는 이제 곧 9기를 모집합니다',\n",
    "    '우리는 열심히 공부합니다',\n",
    "    '우리는 내일도 내일또 공부합니다'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0871d13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 사용한 피처는 무엇인지 확인하는 것! ['9기를' 'bda는' '같습니다' '공부합니다' '날씨는' '내일' '내일도' '내일또' '내일은' '매우' '모두'\n",
      " '모집합니다' '비가' '열심히' '오늘' '우리는' '우산을' '이제' '좋습니다' '좋을까요' '준비하세요']\n",
      "----\n",
      "내가 원하는 메트릭스를 보고 싶다! [[0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "\n",
    "# 문서를 벡터화\n",
    "X =cv.fit_transform(corpus_ko)\n",
    "\n",
    "# 변환 결과를 출력\n",
    "print('corpus 사용한 피처는 무엇인지 확인하는 것!',cv.get_feature_names_out())\n",
    "print('----')\n",
    "print('내가 원하는 메트릭스를 보고 싶다!',X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89d81b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 추가하기!\n",
    "stop_words = ['bda는']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3eef5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus 사용한 피처는 무엇인지 확인하는 것! ['9기를' '같습니다' '공부합니다' '날씨는' '내일' '내일도' '내일또' '내일은' '매우' '모두' '모집합니다' '비가'\n",
      " '열심히' '오늘' '우리는' '우산을' '이제' '좋습니다' '좋을까요' '준비하세요']\n",
      "----\n",
      "내가 원하는 메트릭스를 보고 싶다! [[0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "cv=CountVectorizer(stop_words = stop_words)\n",
    "\n",
    "# 문서를 벡터화\n",
    "X =cv.fit_transform(corpus_ko)\n",
    "\n",
    "# 변환 결과를 출력\n",
    "print('corpus 사용한 피처는 무엇인지 확인하는 것!',cv.get_feature_names_out())\n",
    "print('----')\n",
    "print('내가 원하는 메트릭스를 보고 싶다!',X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ae80019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "## 7x20 \n",
    "## 7개의 문서의 의미 즉 위에 텍스트의 의미\n",
    "## 20 고유 단어 수로 벡터화된 특징 수 \n",
    "## 행렬에서 0이 아닌 요소의 수를 7* 20 = 140 전체\n",
    "## 25 0이 아닌 요소가 25개, 나머지는 모두 0이다.\n",
    "## 희소한지의 비율 0의 비율 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d099a11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "140-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce9d3c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0의 희소에 대한 비율 계산\n",
    "115/140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f39ab5",
   "metadata": {},
   "source": [
    "### Bow ( Bag of Words ) 말뭉치에 한계가 있어서 -> TF-IDF의 방식을 사용한다.\n",
    "\n",
    "- 카운트 벡터는 빈도가 높을수록 중요한 단어 아닌가? \n",
    "- 모든 문서에 동일하게 특정 키워드가 계속 나오면 이게 과연 중요한 건가?\n",
    "- 여러분, 여러분 여러분, 단순하게 카운팅으로 봐서 빈도가 높으면 다 중요한가?\n",
    "\n",
    "- 단어가 더 많은 문서에서 나타날수록 오히려 그 단어는 별로 중요하지 않다. \n",
    "- TF-IDF ( Term Frequency - Inverse Document Frequency ) 단어빈도 - 역문서빈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26099e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
